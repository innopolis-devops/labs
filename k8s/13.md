# K8s StatefulSet

## Running replicas (python)

I changed files `statefulset.yaml`  and `values.yaml`, then I updated the chart:

```
$ helm secrets upgrade python-app-helm ./python-app-helm -n default -f ./python-app-helm/secrets.yaml
Release "python-app-helm" has been upgraded. Happy Helming!
NAME: python-app-helm
LAST DEPLOYED: Mon Nov 28 19:39:52 2022
NAMESPACE: default
STATUS: deployed
REVISION: 2
NOTES:
1. Get the application URL by running these commands:
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace default svc -w python-app-helm'
  export SERVICE_IP=$(kubectl get svc --namespace default python-app-helm --template "{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}")
  echo http://$SERVICE_IP:80
removed './python-app-helm/secrets.yaml.dec'
```

Check the pods:

```
$ kubectl get po,sts,svc,pvc                                                                         
NAME                    READY   STATUS    RESTARTS   AGE
pod/python-app-helm-0   1/1     Running   0          110s
pod/python-app-helm-1   1/1     Running   0          110s

NAME                               READY   AGE
statefulset.apps/python-app-helm   2/2     110s

NAME                      TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/kubernetes        ClusterIP      10.96.0.1       <none>        443/TCP        27d
service/python-app-helm   LoadBalancer   10.96.108.150   <pending>     80:30865/TCP   110s

NAME                                                        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/persistent-volume-python-app-helm-0   Bound    pvc-3ee60d00-a001-4c39-9bbf-246f761abc63   128Mi      RWO            standard       18h
persistentvolumeclaim/persistent-volume-python-app-helm-1   Bound    pvc-3165f722-e281-45f2-b478-cbe2a49936c8   128Mi      RWO            standard       18h
```

Check the visits:

```
$ kubectl exec pod/python-app-helm-0 -- cat persistent/visits.json
28.11.2022 19:41:44
28.11.2022 19:41:44
28.11.2022 19:41:44
28.11.2022 19:41:54
28.11.2022 19:41:54
28.11.2022 19:41:56

$ kubectl exec pod/python-app-helm-1 -- cat persistent/visits.json
28.11.2022 19:40:28
28.11.2022 19:40:29
28.11.2022 19:40:38
28.11.2022 19:40:38
28.11.2022 19:40:48
28.11.2022 19:40:58
28.11.2022 19:41:08
28.11.2022 19:41:44
```

We can see the different output for each replica. 
It happens because each replica have its own persistent volume, and load balancer distribute the requests between them.


## Ordering

* **Why ordering is unnecessary for our app?**

    In our app replicas are independent of each other. They can work perfect separately with different order.

* **How to tell to the StatefulSet controller to launch or terminate all Pods in parallel?**
    
    Add following to the file `statefulset.yaml`:
    ```
    spec:
        podManagementPolicy: "Parallel"
    ```

## Running replicas (golang) - bonus

```
$ helm install go-app-helm ./go-app-helm -n default -f ./go-app-helm/secrets.yaml
NAME: go-app-helm
LAST DEPLOYED: Mon Nov 28 22:21:07 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
1. Get the application URL by running these commands:
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace default svc -w go-app-helm'
  export SERVICE_IP=$(kubectl get svc --namespace default go-app-helm --template "{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}")
  echo http://$SERVICE_IP:80
```

Check the pods:

```
$ kubectl get po,sts,svc,pvc
NAME                READY   STATUS    RESTARTS   AGE
pod/go-app-helm-0   1/1     Running   0          13s
pod/go-app-helm-1   1/1     Running   0          13s

NAME                           READY   AGE
statefulset.apps/go-app-helm   2/2     13s

NAME                  TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
service/go-app-helm   LoadBalancer   10.104.57.22   <pending>     80:31219/TCP   13s
service/kubernetes    ClusterIP      10.96.0.1      <none>        443/TCP        27d

NAME                                                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/persistent-volume-go-app-helm-0   Bound    pvc-50b54620-8e20-4f49-99dd-8bed07b69ffd   128Mi      RWO            standard       13s
persistentvolumeclaim/persistent-volume-go-app-helm-1   Bound    pvc-6265bd6a-71a3-4d3e-a628-87c5bfefbfc5   128Mi      RWO            standard       13s
```

Check the visits:

```
$ kubectl exec pod/go-app-helm-0 -- cat persistent/visits.json
2022-11-28 22:22:44.436459761 +0300 MSK
2022-11-28 22:22:46.708184678 +0300 MSK
2022-11-28 22:22:47.502401315 +0300 MSK
2022-11-28 22:22:57.590819446 +0300 MSK
2022-11-28 22:23:11.202799182 +0300 MSK

$ kubectl exec pod/go-app-helm-1 -- cat persistent/visits.json
2022-11-28 22:22:44.373013107 +0300 MSK
2022-11-28 22:22:46.731330811 +0300 MSK
2022-11-28 22:22:47.474102642 +0300 MSK
2022-11-28 22:23:05.607907944 +0300 MSK
2022-11-28 22:23:06.306945714 +0300 MSK
2022-11-28 22:23:15.75212066 +0300 MSK
2022-11-28 22:23:15.785614153 +0300 MSK
```

## Update strategies - bonus

* OnDelete - it needs to delete the pod manually for the changes to take effect
* RollingUpdate - is an automated update process. In this, the controller deletes and then recreates each of its pods. Pods get updated one at a time.
* BlueGreen - Blue is running the current deployment and the Green is the new deployment to which we want to upgrade. Switch the load balancer to route traffic to the Green environment, then delete the Blue environment once the Green environment is verified