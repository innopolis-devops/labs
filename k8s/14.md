# 14

## K8s

### Kube Prometheus Stack components

* The [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator)
  * Helps with configuration, management, and deployment of Prometheus and related stuff (described below) in Kubernetes environment. Basically some kind of helper/operator (as it says in the name lol).
* [Prometheus](https://prometheus.io/)
  * Collects, processes, and stores(?) monitoring data. Can send alerts to Alertmanager.
  * Metrics increase system observability, allow to see if some failures happen. In large systems they alse need to be aggregated, processed, and presented in a nice way.
* [Alertmanager](https://github.com/prometheus/alertmanager)
  * Manages alerts sent by Prometheus or other apps/sources.
  * The sources are only responsible for generating alerts, such entity can aggregate, process, and route them.
* [Prometheus node-exporter](https://github.com/prometheus/node_exporter)
  * Module that is installed onto a system/node. It collects metrics about running *NIX machine. For example, CPU utilization, RAM usage, disk space, and many more. Then it formats them and serves to Prometheus on request.
  * It is kind of Prometheus adapter for collecting data about the machine.
* [Prometheus Adapter for Kubernetes Metrics APIs](https://github.com/kubernetes-sigs/prometheus-adapter)
  * Converts (adapts) kubernetes metrics for Prometheus.
  * Kubernetes has its own metrics API for node/pod resourses, custom, and external metrics. It usually uses it to, for example, do autoscaling. If we want to collect them, we need to make it available to Prometheus (e.g. to fit its format). This adapter allows this.
* [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)
  * Generates and exports metrics for Kubernetes objects by listening to API server.
  * The metrics aggregators work with predefined format, so such exporters that prepare them are needed.
* [Grafana](https://grafana.com/)
  * Visualization tool with dashboards.
  * It is usually hard to interpret raw data for humans, thus such tool dramatically help to see what is happening in graphs, charts, and in general convenient UI.

### Chart installation

`kubectl get po,sts,svc,pvc,cm` command lists the following resources (in order, according to `kubectl api-resources`):

* Pods
* StatefulSets
* Services
* PersistentVolumeClaims
* ConfigMaps

```bash
$ kubectl get po,sts,svc,pvc,cm 
NAME                                                         READY   STATUS      RESTARTS      AGE
pod/42.1.1-kube-prometheus-sta-admission-create-bkpsp        0/1     Completed   0             3m43s
pod/alertmanager-prom-stack-kube-prometheus-alertmanager-0   2/2     Running     1 (63s ago)   97s
pod/prom-stack-grafana-6664b85869-hh9xr                      3/3     Running     0             2m24s
pod/prom-stack-kube-prometheus-operator-5df6db8547-lqjzw     1/1     Running     0             2m24s
pod/prom-stack-kube-state-metrics-7d59cbd9b-qz54l            1/1     Running     0             2m24s
pod/prom-stack-prometheus-node-exporter-t6zg2                1/1     Running     0             2m24s
pod/prometheus-prom-stack-kube-prometheus-prometheus-0       2/2     Running     0             97s
pod/time-web-app-python-0                                    1/1     Running     0             9m49s
pod/time-web-app-python-1                                    1/1     Running     0             9m49s
pod/time-web-app-rust-0                                      1/1     Running     0             8m27s
pod/time-web-app-rust-1                                      1/1     Running     0             8m27s

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-prom-stack-kube-prometheus-alertmanager   1/1     97s
statefulset.apps/prometheus-prom-stack-kube-prometheus-prometheus       1/1     97s
statefulset.apps/time-web-app-python                                    2/2     9m50s
statefulset.apps/time-web-app-rust                                      2/2     8m27s

NAME                                              TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/alertmanager-operated                     ClusterIP      None             <none>        9093/TCP,9094/TCP,9094/UDP   97s
service/kubernetes                                ClusterIP      10.96.0.1        <none>        443/TCP                      15m
service/prom-stack-grafana                        ClusterIP      10.98.76.71      <none>        80/TCP                       2m24s
service/prom-stack-kube-prometheus-alertmanager   ClusterIP      10.107.212.34    <none>        9093/TCP                     2m24s
service/prom-stack-kube-prometheus-operator       ClusterIP      10.109.184.57    <none>        443/TCP                      2m24s
service/prom-stack-kube-prometheus-prometheus     ClusterIP      10.111.216.56    <none>        9090/TCP                     2m24s
service/prom-stack-kube-state-metrics             ClusterIP      10.110.127.83    <none>        8080/TCP                     2m24s
service/prom-stack-prometheus-node-exporter       ClusterIP      10.105.40.235    <none>        9100/TCP                     2m24s
service/prometheus-operated                       ClusterIP      None             <none>        9090/TCP                     97s
service/time-web-app-python                       LoadBalancer   10.110.134.225   <pending>     80:31004/TCP                 9m50s
service/time-web-app-rust                         LoadBalancer   10.107.91.49     <pending>     80:31296/TCP                 8m27s

NAME                                                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/persistent-volume-time-web-app-python-0   Bound    pvc-9deadd71-8ce2-4524-940e-37050c209988   64Mi       RWO            standard       9m49s
persistentvolumeclaim/persistent-volume-time-web-app-python-1   Bound    pvc-85249af1-0dac-4f29-aa1b-745fbd8d6b50   64Mi       RWO            standard       9m49s
persistentvolumeclaim/persistent-volume-time-web-app-rust-0     Bound    pvc-50f6968f-e9ed-4d42-bbae-e5671d6580cb   64Mi       RWO            standard       8m27s
persistentvolumeclaim/persistent-volume-time-web-app-rust-1     Bound    pvc-ff218f7c-e227-401e-bf79-321d8e30659e   64Mi       RWO            standard       8m27s

NAME                                                                     DATA   AGE
configmap/kube-root-ca.crt                                               1      15m
configmap/prom-stack-grafana                                             1      2m24s
configmap/prom-stack-grafana-config-dashboards                           1      2m24s
configmap/prom-stack-kube-prometheus-alertmanager-overview               1      2m24s
configmap/prom-stack-kube-prometheus-apiserver                           1      2m24s
configmap/prom-stack-kube-prometheus-cluster-total                       1      2m24s
configmap/prom-stack-kube-prometheus-controller-manager                  1      2m24s
configmap/prom-stack-kube-prometheus-etcd                                1      2m24s
configmap/prom-stack-kube-prometheus-grafana-datasource                  1      2m24s
configmap/prom-stack-kube-prometheus-grafana-overview                    1      2m24s
configmap/prom-stack-kube-prometheus-k8s-coredns                         1      2m24s
configmap/prom-stack-kube-prometheus-k8s-resources-cluster               1      2m24s
configmap/prom-stack-kube-prometheus-k8s-resources-namespace             1      2m24s
configmap/prom-stack-kube-prometheus-k8s-resources-node                  1      2m24s
configmap/prom-stack-kube-prometheus-k8s-resources-pod                   1      2m24s
configmap/prom-stack-kube-prometheus-k8s-resources-workload              1      2m24s
configmap/prom-stack-kube-prometheus-k8s-resources-workloads-namespace   1      2m24s
configmap/prom-stack-kube-prometheus-kubelet                             1      2m24s
configmap/prom-stack-kube-prometheus-namespace-by-pod                    1      2m24s
configmap/prom-stack-kube-prometheus-namespace-by-workload               1      2m24s
configmap/prom-stack-kube-prometheus-node-cluster-rsrc-use               1      2m24s
configmap/prom-stack-kube-prometheus-node-rsrc-use                       1      2m24s
configmap/prom-stack-kube-prometheus-nodes                               1      2m24s
configmap/prom-stack-kube-prometheus-nodes-darwin                        1      2m24s
configmap/prom-stack-kube-prometheus-persistentvolumesusage              1      2m24s
configmap/prom-stack-kube-prometheus-pod-total                           1      2m24s
configmap/prom-stack-kube-prometheus-prometheus                          1      2m24s
configmap/prom-stack-kube-prometheus-proxy                               1      2m24s
configmap/prom-stack-kube-prometheus-scheduler                           1      2m24s
configmap/prom-stack-kube-prometheus-workload-total                      1      2m24s
configmap/prometheus-prom-stack-kube-prometheus-prometheus-rulefiles-0   29     97s
configmap/time-web-app-python-config                                     1      9m50s
configmap/time-web-app-rust-config                                       1      8m27s
```

Also by default grafana service is not exposed outside the Kubernetes cluster. To fix it, I've changed the Grafana service type to `NodePort` with `kubectl edit svc prom-stack-grafana`.

### Cluster info

Unfortunately, default dashboards did not work as expected. The same problem as in this issue from [28th of August](https://github.com/prometheus-operator/kube-prometheus/issues/1850) occurs.

![no data](https://i.imgur.com/EadtaMs.png)

Therefore, only parts iii, iv, and vi are solveable:

#### III

![Memory usage](https://i.imgur.com/miWn6Qo.png)

#### IV

![Kubelet pods containers](https://i.imgur.com/6qNMmQz.png)

#### VI

![Alerts #](https://i.imgur.com/0N9fCCY.png)

### Init containers

I chose to download SORA mainnet genesis block data in JSON format.

Init container successfully downloads and saves it:

```bash
$ kubectl exec pod/time-web-app-rust-0 -- cat ./block-data/sora_mainnet_genesis_block.json
Defaulted container "time-web-app-rust" out of: time-web-app-rust, download-file (init)
{"code":0,"message":"Success","generated_at":1670267559,"data":{"block_num":0,"block_timestamp":0,"hash":"0x7e4e32d0feafd4f9c9414b0be86373f9a1efa904809b683453a9af6856d38ad5","parent_hash":"0x0000000000000000000000000000000000000000000000000000000000000000","state_root":"0xeef5ad0eb11c9c61de7d887ab470b1f823dc60532d3ebe89d90ddb50d43655c7","extrinsics_root":"0x03170a2e7597b7b7e3d84c05391d139a62b157e78786d8c082f29dcf4c111314","extrinsics":null,"events":null,"logs":null,"event_count":0,"extrinsics_count":0,"spec_version":1,"validator":"","finalized":true,"account_display":null}}
```

As you can see by hash value (and parent hash), it is indeed [the genesis block](https://sora.subscan.io/block/0).

## Bonus

### App monitoring collection

I've added `ServiceMonitor` object according to [Getting started guide](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/getting-started.md)

It appeared after install of the chart:

```bash
$ kubectl get smon | grep rust
time-web-app-rust                                    89s
```

Also I had to add some labels to make it visible to the operator. Now it retrieves metrics successfully:

![aboba](https://i.imgur.com/gsTTj4r.png)

![abeba](https://i.imgur.com/JcoFAIq.png)

### Init queue

Example in file `init_queue_bonus.yaml` produces this result:

![example](https://i.imgur.com/DL2lp0a.png)
